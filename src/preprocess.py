# -*- coding: utf-8 -*-
"""Get_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RRqQh-dtEiGqUzq8_ULaGQFrTUyamqeb
"""

# !pip install numpy
# !pip install torch
# !pip install faiss-cpu
# !pip install tensorboard
# !pip install transformers

import os
import sys
import json
from pathlib import Path
import csv
import torch


# 初始路径设置
# save_dir = Path("../open_domain_data")
# dir_path = save_dir / "download"

def get_passage_idxs(count: int, passage_idx):
    """
    找到count个问答对对应的passage下标

    return:
      list(list(int))
    """
    if count == -1:
        count = len(passage_idx)

    passage_idxs = []
    for i in range(min(count, len(passage_idx))):
        passage_idxs.append([eval(i) for i in passage_idx[str(i)]])
    return passage_idxs


def get_passages(passage_path: str, passage_idxs: list):
    """
    :param passage_path: 提供数据存储路径
    :param passage_idxs: 提供待抽取数据下标
    :return:dictionary {passage_id : (passage_text,passage_title)}
    """
    if not os.path.exists(passage_path):
        print(f"{passage_path} not exist")
        return

    print(f"loading data from {passage_path}")
    temp_idxs = torch.tensor(passage_idxs)
    temp_idxs.resize_(1, temp_idxs.shape[0] * temp_idxs.shape[1])
    temp_idxs = temp_idxs[0]

    # print(torch.min(temp_idxs))
    total_cnt = len(temp_idxs)
    # print(f"Total:{total_cnt}")

    passages = {}
    cnt = 0
    with open(passage_path) as fin:
        reader = csv.reader(fin, delimiter = '\t')
        for k, row in enumerate(reader):
            if not row[0] == 'id' and eval(row[0]) in temp_idxs:
                # tuple type
                cnt += 1
                if cnt % 500 == 0:
                    print(f"{cnt}/{total_cnt}")
                try:
                    passages[str(row[0])] = (row[1], row[2])
                except:
                    print(f"not correctly loaded:{row}")

    return passages


def gen_examples_NQ(data, index, passages, passages_index):
    """
    :param data: original question answering pairs
    :param index: 挑选出来的问答对的下标
    :param passages: original passages
    :param passages_index: 问答对对应的文章id
    :return: [{question,answers,ctxs:{id,title,text}}]
    """
    res_data = []
    for i, question_context in enumerate(passages_index):
        ctxs = [
            {
                'id': str(passage_id),
                'title': passages[str(passage_id)][1],
                'text': passages[str(passage_id)][0],
            }
            for passage_id in question_context
        ]
        question_id = index[i]
        dico = {
            "question": data[question_id]['question'],
            "answers": data[question_id]['answer'],
            'ctxs': ctxs,
        }
        res_data.append(dico)
    return res_data


if __name__ == '__main__':
    dir_path = Path(sys.argv[1])
    save_dir = Path(sys.argv[2])

    # 读取数据
    NQ_idx = {}  # 问题id
    NQ_passages = {}  # 问题id对应的上下文id
    for split in ['train', 'dev', 'test']:
        with open(dir_path / ('NQ.' + split + '.idx.json'), 'r') as fin:
            NQ_idx[split] = json.load(fin)
        with open(dir_path / 'nq_passages' / (split + '.json'), 'r') as fin:
            NQ_passages[split] = json.load(fin)

    # 初始训练使用的问答对
    originaltrain, originaldev = [], []
    with open(dir_path / 'NQ-open.dev.jsonl') as fin:
        for k, example in enumerate(fin):
            example = json.loads(example)
            originaldev.append(example)

    with open(dir_path / 'NQ-open.train.jsonl') as fin:
        for k, example in enumerate(fin):
            example = json.loads(example)
            originaltrain.append(example)

    # 抽取前200个问题的passages
    train_passage_idxs = get_passage_idxs(200, NQ_passages["train"])
    dev_passage_idxs = get_passage_idxs(200, NQ_passages["dev"])
    test_passage_idxs = get_passage_idxs(200, NQ_passages["test"])

    passages_path = save_dir / 'psgs_w100.tsv'
    passage_path_save = save_dir / "filter_passages"
    passage_path_save.mkdir(parents = True, exist_ok = True)

    train_passages = get_passages(passages_path, train_passage_idxs)
    with open(passage_path_save / "train.json", "w") as f:
        json.dump(train_passages, f, indent = 4)

    dev_passages = get_passages(passages_path, dev_passage_idxs)
    with open(passage_path_save / "dev.json", "w") as f:
        json.dump(dev_passages, f, indent = 4)

    test_passages = get_passages(passages_path, test_passage_idxs)
    with open(passage_path_save / "test.json", "w") as f:
        json.dump(test_passages, f, indent = 4)

    #  生成可用的数据
    NQ_train = gen_examples_NQ(originaltrain, NQ_idx['train'], train_passages, train_passage_idxs)
    NQ_dev = gen_examples_NQ(originaltrain, NQ_idx['dev'], dev_passages, dev_passage_idxs)
    NQ_test = gen_examples_NQ(originaltrain, NQ_idx['test'], test_passages, test_passage_idxs)

    save_NQ = save_dir / "NQ"
    save_NQ.mkdir(parents = True, exist_ok = True)

    with open(save_NQ / "train.json", "w") as fout:
        json.dump(NQ_train, fout, indent = 4)

    with open(save_NQ / "dev.json", "w") as fout:
        json.dump(NQ_dev, fout, indent = 4)

    with open(save_NQ / "test.json", "w") as fout:
        json.dump(NQ_test, fout, indent = 4)
